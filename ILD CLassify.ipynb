{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ae844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.2.1+cu121\n",
      "Uninstalling torch-2.2.1+cu121:\n",
      "  Successfully uninstalled torch-2.2.1+cu121\n",
      "Found existing installation: torchvision 0.17.1+cu121\n",
      "Uninstalling torchvision-0.17.1+cu121:\n",
      "  Successfully uninstalled torchvision-0.17.1+cu121\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121\n",
      "Collecting torchvision==0.17.1+cu121\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.17.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from torchvision==0.17.1+cu121) (2.3.1)\n",
      "Collecting torch==2.2.1 (from torchvision==0.17.1+cu121)\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.2.1%2Bcu121-cp312-cp312-linux_x86_64.whl (757.2 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from torchvision==0.17.1+cu121) (11.3.0)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (4.14.1)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch==2.2.1->torchvision==0.17.1+cu121) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->torchvision==0.17.1+cu121) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch==2.2.1->torchvision==0.17.1+cu121) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch==2.2.1->torchvision==0.17.1+cu121) (1.3.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [torch]\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
      "\u001b[1A\u001b[2KSuccessfully installed torch-2.2.1+cu121 torchvision-0.17.1+cu121\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchsummary in /usr/local/python/3.12.1/lib/python3.12/site-packages (1.5.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting captum==0.7.0\n",
      "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (from captum==0.7.0) (3.10.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from captum==0.7.0) (2.3.1)\n",
      "Requirement already satisfied: torch>=1.6 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from captum==0.7.0) (2.2.1+cu121)\n",
      "Collecting tqdm (from captum==0.7.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (4.14.1)\n",
      "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/codespace/.local/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from torch>=1.6->captum==0.7.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6->captum==0.7.0) (12.8.93)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch>=1.6->captum==0.7.0) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (4.58.5)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib->captum==0.7.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->captum==0.7.0) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy->torch>=1.6->captum==0.7.0) (1.3.0)\n",
      "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, captum\n",
      "\u001b[?25l\u001b[33m  WARNING: The script tqdm is installed in '/usr/local/python/3.12.1/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [captum]2m1/2\u001b[0m [captum]\n",
      "\u001b[1A\u001b[2KSuccessfully installed captum-0.7.0 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# install torchvision compatible with torch==2.2.1+cu121\n",
    "%pip install torchvision==0.17.1+cu121 --extra-index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# install torchsummary\n",
    "%pip install torchsummary\n",
    "\n",
    "#install captum\n",
    "%pip install captum==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc369f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pip\n",
    "#python3 -m pip install --upgrade pip\n",
    "import glob\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "\n",
    "from captum.attr import Occlusion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113d7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttentionBlock(nn.Module):\n",
    "    def __init__(self, channel, ratio):\n",
    "        super(ChannelAttentionBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1).to(device)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1).to(device)\n",
    "        self.fc1 = nn.Linear(channel, channel // ratio).to(device)\n",
    "        self.fc2 = nn.Linear(channel // ratio, channel).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_pool = self.avg_pool(x)\n",
    "        avg_pool = avg_pool.view(avg_pool.size(0), -1)\n",
    "        avg_pool = self.fc2(F.relu(self.fc1(avg_pool)))\n",
    "\n",
    "        max_pool = self.max_pool(x)\n",
    "        max_pool = max_pool.view(max_pool.size(0), -1)\n",
    "        max_pool = self.fc2(F.relu(self.fc1(max_pool)))\n",
    "\n",
    "        scale = torch.sigmoid(avg_pool + max_pool)\n",
    "        scale = scale.view(scale.size(0), scale.size(1), 1, 1)\n",
    "        \n",
    "        return x * scale\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d686de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionBlock(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttentionBlock, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=self.kernel_size, stride=1, padding=self.kernel_size // 2, bias=False)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "    def forward(self, input_feature):\n",
    "        r, c = input_feature.size(-2), input_feature.size(-1)\n",
    "        avg_pool = torch.mean(input_feature, dim=1, keepdim=True).to(device)\n",
    "        max_pool = torch.max(input_feature, dim=1, keepdim=True)[0].to(device)\n",
    "        concat = torch.cat([avg_pool, max_pool], dim=1).to(device)\n",
    "        \n",
    "        concat = self.conv(concat)\n",
    "        \n",
    "        concat = torch.sigmoid(concat)\n",
    "        concat = concat.view(-1, 1, r, c)\n",
    "        \n",
    "        return input_feature * concat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d21ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam_block(i, ratio=8):\n",
    "        attention_feature = ChannelAttentionBlock(i, ratio=ratio).to(device)\n",
    "        attention_feature = SpatialAttentionBlock().to(device)\n",
    "        return attention_feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daeb344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, padding=padding, groups=in_channels)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM(nn.Module) :\n",
    "    def __init__(self, c) :\n",
    "        super(BM, self).__init__()\n",
    "        self.c = c\n",
    "        self.inter = c // 2  # Intermediate dimension for attention\n",
    "         \n",
    "        #channel attention\n",
    "        self.channel_attention = ChannelAttentionBlock(c, ratio=8)\n",
    "\n",
    "        # Contextual feature extraction (global context)\n",
    "        self.g = nn.Conv2d(self.c, self.inter, kernel_size=1, padding=\"same\")\n",
    "        self.theta = nn.Conv2d(self.c, self.inter, kernel_size=1, padding=\"same\")\n",
    "        self.phi = nn.Conv2d(self.c, self.inter, kernel_size=1, padding=\"same\")\n",
    "\n",
    "        # Local context feature extraction \n",
    "        self.local_context = nn.Sequential(\n",
    "            \n",
    "            DepthwiseSeparableConv(self.c, self.inter, kernel_size=3, padding=\"same\"),\n",
    "            nn.Dropout(p=0.1)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # Spatial attention mechanism\n",
    "        self.spatial_attention = SpatialAttentionBlock()\n",
    "        self.conv = nn.Conv2d(self.inter, 1, kernel_size=1, padding=\"same\")\n",
    "\n",
    "        # Multi-scale context extraction (global + local)\n",
    "        self.multi_scale_conv = nn.Sequential(\n",
    "            DepthwiseSeparableConv(self.inter, self.inter, kernel_size=1, padding=\"same\"),\n",
    "            nn.Dropout(p=0.3),\n",
    "            DepthwiseSeparableConv(self.inter, self.inter, kernel_size=3, padding=\"same\"),\n",
    "            nn.Dropout(p=0.2),\n",
    "            \n",
    "        )\n",
    "        \n",
    "\n",
    "        # Adaptive weighting for global and local context\n",
    "        self.global_weight = nn.Parameter(torch.ones(1))  # Learnable scalar weight\n",
    "        self.local_weight = nn.Parameter(torch.ones(1))   # Learnable scalar weight\n",
    "\n",
    "        # Final output transformation (to match input dimensions)\n",
    "        self.W = nn.Sequential(\n",
    "            nn.Conv2d(self.inter, self.c, kernel_size=1, padding=\"same\"),\n",
    "            \n",
    "            nn.BatchNorm2d(self.c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "       \n",
    "        nn.init.constant_(self.W[1].weight, 0)\n",
    "        nn.init.constant_(self.W[1].bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #the exact logic of BM attention is currently a placeholder only. \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convbatch(i, k, d, f):\n",
    "    conv = nn.Conv2d(i, f, kernel_size=k, dilation=d, padding = \"same\")\n",
    "    nn.init.xavier_uniform_(conv.weight)\n",
    "    batch_norm = nn.BatchNorm2d(f)\n",
    "    return nn.Sequential(conv, batch_norm, nn.ReLU())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab42644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSconv(nn.Module):\n",
    "    def __init__(self, i, k, d, f, angle):\n",
    "        super(RSconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(i, f, kernel_size=k, dilation=d, padding= 'same')\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        self.conv.weight = nn.Parameter(self.conv.weight, requires_grad=True)\n",
    "        self.conv.bias = nn.Parameter(self.conv.bias, requires_grad=True)\n",
    "        self.bn = nn.BatchNorm2d(f, track_running_stats=True)\n",
    "        self.bn.weight.requires_grad = True\n",
    "        self.bn.bias.requires_grad = True\n",
    "        self.angle = nn.Parameter(torch.zeros(1), requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        #the exact logic of RSconv is currently a placeholder only. \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1047af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVconv(nn.Module) :\n",
    "    def __init__(self, i, k, d, f):\n",
    "        super(SVconv, self).__init__()\n",
    "        #kernel size\n",
    "        self.k = k\n",
    "        #dilation rate\n",
    "        self.d = d\n",
    "        #receptive field size\n",
    "        self.rf = (k - 1) * d + 1\n",
    "        #learnable mask for kernel\n",
    "        self.mask = nn.Parameter(torch.rand(self.rf, self.rf))\n",
    "        #kernel W\n",
    "        self.weight = nn.Parameter(torch.randn(f, i, self.rf, self.rf))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.bn = nn.BatchNorm2d(f, track_running_stats=True)\n",
    "        self.bn.weight.requires_grad = True\n",
    "        self.bn.bias.requires_grad = True\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        #the exact logic of SVconv is currently a placeholder only. \n",
    "        return \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "         \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b1278",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ATKPool(nn.Module):\n",
    "    #Code for average top-k pooling\n",
    "    def __init__(self, initial_k=1):\n",
    "        super(ATKPool, self).__init__()\n",
    "        self.k = nn.Parameter(torch.tensor(float(initial_k)))\n",
    "    def forward(self, input):\n",
    "        batch_size, channels, height, width = input.size()\n",
    "        k = torch.clamp(self.k, min=1, max=2**2).int()\n",
    "        unfolded = F.unfold(input, kernel_size = 2, stride = 2)\n",
    "        unfolded = unfolded.view(batch_size, channels, 2 * 2, -1)\n",
    "        unfolded, _ = torch.sort(unfolded.clone(), dim=2, descending=True)\n",
    "        top_k_values = unfolded[:, :, :k].clone()\n",
    "        avg_top_k = top_k_values.mean(dim=2)\n",
    "        newheight = (height + 2 - 2) // 2 \n",
    "        newwidth = (width + 2 - 2) // 2\n",
    "        atkp  = avg_top_k.view(batch_size, channels, newheight, newwidth)\n",
    "        return atkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff844979",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RESP(nn.Module):\n",
    "    def __init__(self, initial_threshold=0.5, initial_k = 1, initial_k1 = 1, initial_weight = 0.5):\n",
    "         super(RESP, self).__init__()\n",
    "         self.max = nn.MaxPool2d(kernel_size=2)\n",
    "         self.threshold = nn.Conv2d(16, 1, kernel_size = 1)\n",
    "         nn.init.constant_(self.threshold.weight, initial_threshold)\n",
    "         nn.init.constant_(self.threshold.bias,  initial_threshold)\n",
    "         self.k = nn.Parameter(torch.tensor(float(initial_k)))\n",
    "         self.k1 = nn.Parameter(torch.tensor(float(initial_k1)))\n",
    "         self.weight = nn.Parameter(torch.tensor(initial_weight))\n",
    "         self.atkp = ATKPool(initial_k)\n",
    "    def forward(self, x):\n",
    "          #the exact logic of RESP is currently a placeholder only.\n",
    "          return   \n",
    "\n",
    "              \n",
    "          \n",
    "\n",
    "         \n",
    "         \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch1(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(Branch1, self).__init__()\n",
    "        self.block = block\n",
    "        #self.device = device\n",
    "        self.initialized = False\n",
    "        self.convbatch1 = RSconv(i=16, k=3, d=1, f=16, angle=torch.zeros(1).to(device))\n",
    "        self.convbatch2 = RSconv(i=16, k=3, d=1, f=16, angle=torch.zeros(1).to(device))\n",
    "        self.convbatch3 = RSconv(i=32, k=3, d=1, f=16, angle=torch.zeros(1).to(device))\n",
    "        self.convbatch4 = RSconv(i=48, k=3, d=1, f=16, angle=torch.zeros(1).to(device))\n",
    "        self.convbatch5 = convbatch(i=16, k=3, d=1, f=16)\n",
    "        self.convbatch6 = convbatch(i=16, k=3, d=1, f=16)\n",
    "        self.convbatch7 = convbatch(i=32, k=3, d=1, f=16)\n",
    "        self.convbatch8 = convbatch(i=48, k=3, d=1, f=16)\n",
    "        self.convbatch = convbatch(i=64, k=1, d=1, f=16)\n",
    "        self.cbam = cbam_block(i=64, ratio=8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "          \n",
    "        if(self.block==1 or self.block==2): \n",
    "           conv1 = self.convbatch1(x)\n",
    "           conv2 = self.convbatch2(conv1)\n",
    "           conv2 = torch.cat([conv1, conv2], dim=1)\n",
    "           conv3 = self.convbatch3(conv2)\n",
    "           conv3 = torch.cat([conv2, conv3], dim=1)\n",
    "           conv4 = self.convbatch4(conv3)\n",
    "           conv4 = torch.cat([conv3, conv4], dim=1)\n",
    "           conv4 = self.cbam(conv4)\n",
    "           conv = self.convbatch(conv4)\n",
    "        elif (self.block==3 or self.block==4):\n",
    "           conv1 = self.convbatch5(x)\n",
    "           conv2 = self.convbatch6(conv1)\n",
    "           conv2 = torch.cat([conv1, conv2], dim=1)\n",
    "           conv3 = self.convbatch7(conv2)\n",
    "           conv3 = torch.cat([conv2, conv3], dim=1)\n",
    "           conv4 = self.convbatch8(conv3)\n",
    "           conv4 = torch.cat([conv3, conv4], dim=1)\n",
    "           conv4 = self.cbam(conv4)\n",
    "           conv = self.convbatch(conv4)\n",
    "        return conv\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0954cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branch2(nn.Module):\n",
    "    def __init__(self, block):\n",
    "        super(Branch2, self).__init__()\n",
    "        self.block = block\n",
    "        self.convbatch1 = convbatch(i=16, k=5, d=1, f=16)\n",
    "        self.convbatch2 = convbatch(i=16, k=5, d=1, f=16)\n",
    "        self.convbatch3 = convbatch(i=32, k=5, d=1, f=16)\n",
    "        self.convbatch4 = convbatch(i=48, k=5, d=1, f=16)\n",
    "        self.convbatch5 = SVconv(i=16, k=3, d=2, f=16)\n",
    "        self.convbatch6 = SVconv(i=16, k=3, d=2, f=16)\n",
    "        self.convbatch7 = SVconv(i=32, k=3, d=2, f=16)\n",
    "        self.convbatch8 = SVconv(i=48, k=3, d=2, f=16)\n",
    "        self.convbatch = convbatch(i=64, k=1, d=1, f=16)\n",
    "        self.cbam = cbam_block(i=64, ratio=8)\n",
    "    def forward(self, x):\n",
    "     if(self.block==1 or self.block==2): \n",
    "        conv1 = self.convbatch1(x)\n",
    "        conv2 = self.convbatch2(conv1)\n",
    "        conv2 = torch.cat([conv1, conv2], dim=1)\n",
    "        conv3 = self.convbatch3(conv2)\n",
    "        conv3 = torch.cat([conv2, conv3], dim=1)\n",
    "        conv4 = self.convbatch4(conv3)\n",
    "        conv4 = torch.cat([conv3, conv4], dim=1)\n",
    "        conv4 = self.cbam(conv4)\n",
    "        conv = self.convbatch(conv4)\n",
    "     \n",
    "     elif(self.block==3 or self.block==4):\n",
    "        conv1 = self.convbatch5(x)\n",
    "        conv2 = self.convbatch6(conv1)\n",
    "        conv2 = torch.cat([conv1, conv2], dim=1)\n",
    "        conv3 = self.convbatch7(conv2)\n",
    "        conv3 = torch.cat([conv2, conv3], dim=1)\n",
    "        conv4 = self.convbatch8(conv3)\n",
    "        conv4 = torch.cat([conv3, conv4], dim=1)\n",
    "        conv4 = self.cbam(conv4)\n",
    "        conv = self.convbatch(conv4)\n",
    "     \n",
    "     return conv\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c5a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(nn.Module):\n",
    "    #This class defines the (overall) LUNG Net architecture \n",
    "    def __init__(self):\n",
    "        super(DenseModel, self).__init__()\n",
    "        \n",
    "        self.angle = nn.Parameter(torch.zeros(1, requires_grad=True))  \n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2).to(device)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv1.weight = nn.Parameter(self.conv1.weight.to(device))\n",
    "        self.norm1 = nn.BatchNorm2d(16).to(device)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, padding=1).to(device)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        self.conv2.weight = nn.Parameter(self.conv2.weight.to(device))\n",
    "        self.norm2 = nn.BatchNorm2d(16).to(device)\n",
    "        self.conv = nn.Conv2d(33, 16, kernel_size=1, padding=0).to(device)\n",
    "        nn.init.xavier_uniform_(self.conv.weight)\n",
    "        self.conv.weight = nn.Parameter(self.conv.weight.to(device))\n",
    "        self.norm = nn.BatchNorm2d(16).to(device)\n",
    "        self.block1conv1 = nn.Conv2d(16, 1, kernel_size=1).to(device)\n",
    "        nn.init.xavier_uniform_(self.block1conv1.weight)\n",
    "        self.block1conv1.weight = nn.Parameter(self.block1conv1.weight.to(device))\n",
    "        self.norm_block1conv1 = nn.BatchNorm2d(1).to(device)\n",
    "        self.block1branch2 = Branch2(1).to(device)\n",
    "        self.block1branch1 = Branch1(1).to(device)\n",
    "        self.block2conv1 = nn.Conv2d(16, 1, kernel_size=1).to(device)\n",
    "        nn.init.xavier_uniform_(self.block2conv1.weight)\n",
    "        self.block2conv1.weight = nn.Parameter(self.block2conv1.weight.to(device))\n",
    "        self.norm_block2conv1 = nn.BatchNorm2d(1).to(device)\n",
    "        self.block2branch2 = Branch2(2).to(device)\n",
    "        self.block2branch1 = Branch1(2).to(device)\n",
    "        self.block3conv1 = nn.Conv2d(16, 1, kernel_size=1).to(device)\n",
    "        nn.init.xavier_uniform_(self.block3conv1.weight)\n",
    "        self.block3conv1.weight = nn.Parameter(self.block3conv1.weight.to(device))\n",
    "        self.norm_block3conv1 = nn.BatchNorm2d(1).to(device)\n",
    "        self.block3branch2 = Branch2(3).to(device)\n",
    "        self.block3branch1 = Branch1(3).to(device)\n",
    "        self.block4conv1 = nn.Conv2d(16, 1, kernel_size=1).to(device)\n",
    "        nn.init.xavier_uniform_(self.block4conv1.weight)\n",
    "        self.block4conv1.weight = nn.Parameter(self.block4conv1.weight.to(device))\n",
    "        self.norm_block4conv1 = nn.BatchNorm2d(1).to(device)\n",
    "        self.block4branch2 = Branch2(4).to(device)\n",
    "        self.block4branch1 = Branch1(4).to(device)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2).to(device)\n",
    "        self.pooling = RESP().to(device)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        #3 dense layers to be defined here\n",
    "        \n",
    "        self.cbam = cbam_block(i=33, ratio=8)\n",
    "        self.BM = BM(c=33)\n",
    "        self.initialized = False\n",
    "    def forward(self, x):\n",
    "          x = self.conv1(x)\n",
    "          \n",
    "          x = F.relu(self.norm1(x))\n",
    "          x = self.conv2(x)\n",
    "          \n",
    "          x = F.relu(self.norm2(x))\n",
    "            \n",
    "          block1conv1 = self.block1conv1(x)\n",
    "          \n",
    "          block1conv1 = F.relu(self.norm_block1conv1(block1conv1))\n",
    "          block1branch2 = self.block1branch2(x)\n",
    "          block1branch1 = self.block1branch1(x)\n",
    "          conc1 = torch.cat([block1branch2, block1branch1], dim=1)\n",
    "          conc1 = torch.cat([conc1, block1conv1], dim=1)\n",
    "          \n",
    "\n",
    "          conc1 = self.cbam(conc1)\n",
    "          conc1 = self.conv(conc1)\n",
    "          \n",
    "          conc1 = F.relu(self.norm(conc1))\n",
    "          \n",
    "\n",
    "          x = self.pool(conc1)\n",
    "          x = self.pool(x)\n",
    "          x = F.dropout(x, p=0.1, training=self.training)\n",
    "\n",
    "\n",
    "          block2conv1 = self.block2conv1(x)\n",
    "          \n",
    "          block2conv1 = F.relu(self.norm_block2conv1(block2conv1))\n",
    "          block2branch2 = self.block2branch2(x)\n",
    "          block2branch1 = self.block2branch1(x)\n",
    "          conc2 = torch.cat([block2branch2, block2branch1], dim=1)\n",
    "          conc2 = torch.cat([conc2, block2conv1], dim=1)\n",
    "          \n",
    "          conc2 = self.cbam(conc2)\n",
    "          conc2 = self.conv(conc2)\n",
    "          \n",
    "          conc2 = F.relu(self.norm(conc2))\n",
    "          \n",
    "\n",
    "          x = self.pool(conc2)\n",
    "          x = self.pool(x)\n",
    "          x = F.dropout(x, p=0.15, training=self.training)\n",
    "\n",
    "          \n",
    "\n",
    "          block3conv1 = self.block3conv1(x)\n",
    "          \n",
    "          block3conv1 = F.relu(self.norm_block3conv1(block3conv1))\n",
    "          block3branch2 = self.block3branch2(x)\n",
    "          block3branch1 = self.block3branch1(x)\n",
    "          conc3 = torch.cat([block3branch2, block3branch1], dim=1)\n",
    "          conc3 = torch.cat([conc3, block3conv1], dim=1)\n",
    "          \n",
    "          conc3 = self.BM(conc3)\n",
    "          conc3 = self.conv(conc3)\n",
    "          \n",
    "          conc3 = F.relu(self.norm(conc3))\n",
    "          \n",
    "\n",
    "          x = self.pooling(conc3)\n",
    "          \n",
    "\n",
    "          block4conv1 = self.block4conv1(x)\n",
    "          \n",
    "          block4conv1 = F.relu(self.norm_block4conv1(block4conv1))\n",
    "          block4branch2 = self.block4branch2(x)\n",
    "          block4branch1 = self.block4branch1(x)\n",
    "          conc4 = torch.cat([block4branch2, block4branch1], dim=1)\n",
    "          conc4 = torch.cat([conc4, block4conv1], dim=1)\n",
    "          conc4 = self.BM(conc4)\n",
    "          conc4 = self.conv(conc4)\n",
    "          \n",
    "          conc4 = F.relu(self.norm(conc4))\n",
    "          \n",
    "          x = self.pooling(conc4)\n",
    "          \n",
    "\n",
    "          x = self.flatten(x)\n",
    "          # x = dense layers to be computed here\n",
    "          \n",
    "\n",
    "          return torch.sigmoid(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "model = DenseModel().to(device)\n",
    "input_size = (1, 512, 512)\n",
    "\n",
    "dummy_input = torch.randn(1, *input_size).to(device)\n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3517b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af25adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#train_dataset = the train dataset is read here\n",
    "#val_dataset = the validation dataset is read here\n",
    "\n",
    "#test_dataset = #the test dataset is read here\n",
    "\n",
    "#train_loader = The train_dataset is to be loaded here\n",
    "#val_loader = The val_dataset is to be loaded here\n",
    "#test_loader = The test_dataset is to be loaded here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "checkpoint_path = \"define the checkpoint path\"\n",
    "class ModelCheckpoint: #The class for model training\n",
    "    def __init__(self, filepath, monitor='val_accuracy', verbose=0, save_best_only=True, mode='max'):\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.mode = mode\n",
    "        self.best_metric = None\n",
    "\n",
    "\n",
    "    def __call__(self, model, optimizer, metric):\n",
    "        if self.best_metric is None or (metric > self.best_metric and self.mode == 'max') or (metric < self.best_metric and self.mode == 'min'):\n",
    "            self.best_metric = metric\n",
    "            if self.verbose:\n",
    "                print(f\"                   Validation {self.monitor}: {metric:.4f} (improved)\")\n",
    "            if self.save_best_only:\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'metric': metric\n",
    "                }, self.filepath)\n",
    "                if self.verbose:\n",
    "                    print(f\"               Best model saved at: {self.filepath}\")\n",
    "\n",
    "# Creating an instance of the model checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(filepath=os.path.join(checkpoint_path, 'best_model.pth'),\n",
    "                                      monitor='val_accuracy',\n",
    "                                      verbose=1,\n",
    "                                      save_best_only=True,\n",
    "                                      mode='max') #checkpoint_path to be defined with actual checkpoint path\n",
    "\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, num_epochs=100):\n",
    "    #The actual training code to be defined here\n",
    "    #This is only a placeholder for the actual training code\n",
    "    return \n",
    "\n",
    "\n",
    "train(model, optimizer, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing (evaluation)\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "#model = Load the model here\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    #This is a placeholder for the actual definition of testing or evaluation.\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
